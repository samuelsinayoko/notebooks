{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!mv /Users/sinayoks/Desktop/Screen\\ Shot\\ 2020-06-27\\ at\\ 14.49.39.png sync_app.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Little Book of Semaphores\n",
    "\n",
    "Working through my own implementations of concurrency and synchronization problems from the [Little Book of Semaphores](http://greenteapress.com/semaphores/LittleBookOfSemaphores.pdf) by A. B. Downey.\n",
    "\n",
    "**Asyncio solutions in notebook**\n",
    "\n",
    "We will implement examples using asyncio. \n",
    "\n",
    "**Reference solutions using Sync GUI app**\n",
    "\n",
    "Solutions are also available from https://github.com/AllenDowney/LittleBookOfSemaphores/tree/master/code/sync_code and can be run using the Sync program provided in that repository:\n",
    "```\n",
    "git clone git@github.com:AllenDowney/LittleBookOfSemaphores.git\n",
    "cd LittleBookOfSemaphores/code\n",
    "python Sync.py sync_code/signal.py\n",
    "```\n",
    "![signalling problem using Downey's Sync app](sync_app.png)\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def run_test(test_coroutine, attempts):\n",
    "    \"\"\"Run a test multiple times to make sure we don't get lucky.\"\"\"\n",
    "    [await test_coroutine(attempt) for attempt in range(attempts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Basic patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Signaling\n",
    "**Signaling problem**\n",
    "2 threads/coroutines having to coordinate to do an action in a particular order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_signaling(attempt):\n",
    "    \"\"\"Check the signaling approach serialises the threads so that actionA \n",
    "    takes place before actionB. \n",
    "    \n",
    "    Push a value from coroutines A then one from coroutine B into a shared queue, \n",
    "    and make sure they've been pushed in that order. \n",
    "    \"\"\"\n",
    "    # Not using a Lock here because we want to signal/release before waiting/acquiring \n",
    "    # so we need a semaphore. \n",
    "    first_action_done = asyncio.Semaphore(0)\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    async def push(value):\n",
    "        await queue.put(value)\n",
    "\n",
    "    async def coroutineA():\n",
    "        \"\"\"Do first action then signal to B that we're done\"\"\"\n",
    "        asyncio.Task.current_task().name = \"coroutineA\"\n",
    "        await push('A')\n",
    "        first_action_done.release()\n",
    "\n",
    "    async def coroutineB():\n",
    "        asyncio.Task.current_task().name = \"coroutineB\"\n",
    "        async with first_action_done:\n",
    "            res = await push('B')\n",
    "\n",
    "\n",
    "    await asyncio.gather(coroutineA(), coroutineB())\n",
    "    res = [await queue.get() for _ in range(queue.qsize())]\n",
    "    assert res == ['A', 'B'], f'Test failed for attempt {attempt}: got {res}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_signaling, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Rendez Vous\n",
    "Two threads must await each other before doing some action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_rendez_vous(attempt):\n",
    "    \"\"\"Make sure action doesn't happen before a rendez vous. \n",
    "    \n",
    "    In this test, the action is reading the key value pairs from a shared dictionary. \n",
    "    Each of the two coroutines adds a key-value pair to the dictionary before the rendez vous. \n",
    "    So if both coroutines have waited for the other one successfully, they should both \n",
    "    return the two same (key,value) pairs. \n",
    "    \"\"\"\n",
    "    b_has_arrived = asyncio.Semaphore(0)\n",
    "    a_has_arrived = asyncio.Semaphore(0)\n",
    "    shared_dict = {}\n",
    "    lock = asyncio.Lock()  # a lock to protect updating the dictionary\n",
    "    \n",
    "    async def read_items_from_dict():\n",
    "        \"\"\"Return tuple of (key, value) pairs giving the items in the dictionary.\"\"\"\n",
    "        async with lock:\n",
    "            res = tuple(sorted(shared_dict.items()))\n",
    "        return res \n",
    "\n",
    "    async def coroutineA(key, value):\n",
    "        \"\"\"Store key value pair in shared dictionary, wait for rendez vous with B, \n",
    "        then read all key value pairs from dictionary. \n",
    "        \"\"\"\n",
    "        a_has_arrived.release()\n",
    "        # put in a value in the queue\n",
    "        async with lock:\n",
    "              shared_dict[key] = value\n",
    "        await b_has_arrived.acquire()\n",
    "        res = await read_items_from_dict()\n",
    "        return res\n",
    "\n",
    "    async def coroutineB(key, value):\n",
    "        \"\"\"Store key value pair in shared dictionary, wait for rendez vous with A, \n",
    "        then read all key value pairs from dictionary. \n",
    "        \"\"\"\n",
    "        b_has_arrived.release()\n",
    "        async with lock:\n",
    "              shared_dict[key] = value\n",
    "        await a_has_arrived.acquire()\n",
    "        res = await read_items_from_dict()\n",
    "        return res\n",
    "\n",
    "    itemsA, itemsB = await asyncio.gather(\n",
    "        coroutineA('A', 1), \n",
    "        coroutineB('B', 2)\n",
    "    )\n",
    "    expected_items = ('A', 1), ('B', 2)\n",
    "    results = {k:v for k,v in locals().items() if k in ['attempt', 'itemsA', 'itemsB', 'expected_items']}\n",
    "    assert itemsA == itemsB == expected_items, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_rendez_vous, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Mutex\n",
    "Protects access to critical regions. Mutal exclusion: two threads can't both have access to the mutex at the same time. \n",
    "\n",
    "How to test:\n",
    "- Use a lot of threads and make them race hard: see `test_mutex_threadpoool`\n",
    "- Better demonstrated without asyncio as the event loop tends to make some of these issues go away because operations between awaits are atomic (there's only one thread). \n",
    "  - we can demonstrate with asyncio by forcing a context switch: see `test_mutex_aio`\n",
    "  - we also can also run the threadpool test using aio `test_mutex_threadpool_aio`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Thread pool test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "def test_mutex_threadpool():\n",
    "    \"\"\"Check we can protect a variable using a mutex. \n",
    "    \n",
    "    Better demonstrated with threads rather than coroutines because with asyncio's event loop\n",
    "    operations between \"awaits\" are atomic.\n",
    "    \n",
    "    Use a big threadpool and make the threads race hard \n",
    "    by all incrementing the counter many times.\n",
    "     \n",
    "    \"\"\"\n",
    "    max_workers=100\n",
    "    pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "    counter = 0\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    iterations = 100_000\n",
    "    def increment_shared_counter(_):\n",
    "        nonlocal counter\n",
    "        with lock:\n",
    "            for _ in range(iterations):\n",
    "                counter += 1\n",
    "        #time.sleep(random.random())\n",
    "        return counter\n",
    "    intermediate_results = list(pool.map(increment_shared_counter, range(max_workers)))\n",
    "    #print(sorted(intermediate_results))\n",
    "    assert counter == iterations * max_workers, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['counter', 'intermediate_results']\n",
    "    }\n",
    "    \n",
    "test_mutex_threadpool() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "##### Thread pool + asyncio test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_mutex_threadpool_aio():\n",
    "    \"\"\"Check we can protect a variable using a mutex. \n",
    "    \n",
    "    Use a big threadpool and make the threads race hard \n",
    "    by all incrementing the counter many times. \n",
    "    \n",
    "    Use asyncio to run the experiment via loop.run_in_executor \n",
    "    \"\"\"\n",
    "    pool = ThreadPoolExecutor(max_workers=100)\n",
    "    lock = threading.Lock()\n",
    "    counter = 0\n",
    "\n",
    "    def increment_shared_counter(_):\n",
    "        nonlocal counter\n",
    "        with lock:\n",
    "            for _ in range(100_000):\n",
    "                counter = counter + 1\n",
    "        #time.sleep(random.random())\n",
    "        return counter\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [\n",
    "        loop.run_in_executor(pool, increment_shared_counter, i) \n",
    "        for i in range(100)\n",
    "    ]\n",
    "    intermediate_results = await asyncio.gather(*tasks)\n",
    "    #print(sorted(intermediate_results))\n",
    "    assert counter == 100_000 * 100, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['counter', 'intermediate_results']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await test_mutex_threadpool_aio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Minimal asyncio test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_mutex_aio():\n",
    "    \"\"\"Check we can protect a variable using a mutex. \n",
    "    \n",
    "    Minimal test with asyncio to force a context switch between \n",
    "    reading and updating the counter. \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    lock = asyncio.Lock()\n",
    "    \n",
    "    async def increment_shared_counter():\n",
    "        nonlocal counter\n",
    "        async with lock:   # fails \n",
    "            # this is a bit convoluted but is a simple way to \n",
    "            # simulating non-thread safe concurrent updates to counter:\n",
    "            # we're sleeping between reading and incrementing the value of counter\n",
    "            # which allows a context switch: without the lock this will fail the test\n",
    "            x = counter\n",
    "            # forcing a context switch by sleeping \n",
    "            await asyncio.sleep(0.001)\n",
    "            counter = x + 1\n",
    "        return counter\n",
    "    tasks = [increment_shared_counter() for _ in range(2)]\n",
    "    intermediate_results = await asyncio.gather(*tasks)\n",
    "    #print(sorted(intermediate_results))\n",
    "    assert counter == 1 * 2, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['counter', 'intermediate_results']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await test_mutex_aio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
