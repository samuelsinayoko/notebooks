{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sinayoks/dev/notebooks/little-book-of-semaphores'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!mv /Users/sinayoks/Desktop/Screen\\ Shot\\ 2020-06-27\\ at\\ 14.49.39.png sync_app.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# The Little Book of Semaphores\n",
    "\n",
    "Working through my own implementations of concurrency and synchronization problems from the [Little Book of Semaphores](http://greenteapress.com/semaphores/LittleBookOfSemaphores.pdf) by A. B. Downey.\n",
    "\n",
    "**Asyncio solutions in notebook**\n",
    "\n",
    "We will implement examples using asyncio. \n",
    "\n",
    "**Reference solutions using Sync GUI app**\n",
    "\n",
    "Solutions are also available from https://github.com/AllenDowney/LittleBookOfSemaphores/tree/master/code/sync_code and can be run using the Sync program provided in that repository:\n",
    "```\n",
    "git clone git@github.com:AllenDowney/LittleBookOfSemaphores.git\n",
    "cd LittleBookOfSemaphores/code\n",
    "python Sync.py sync_code/signal.py\n",
    "```\n",
    "![signalling problem using Downey's Sync app](sync_app.png)\n",
    "```\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def run_test(test_coroutine, attempts):\n",
    "    \"\"\"Run a test multiple times to make sure we don't get lucky.\"\"\"\n",
    "    [await test_coroutine(attempt) for attempt in range(attempts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Basic patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Signaling\n",
    "**Signaling problem**\n",
    "2 threads/coroutines having to coordinate to do an action in a particular order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_signaling(attempt):\n",
    "    \"\"\"Check the signaling approach serialises the threads so that actionA \n",
    "    takes place before actionB. \n",
    "    \n",
    "    Push a value from coroutines A then one from coroutine B into a shared queue, \n",
    "    and make sure they've been pushed in that order. \n",
    "    \"\"\"\n",
    "    # Not using a Lock here because we want to signal/release before waiting/acquiring \n",
    "    # so we need a semaphore. \n",
    "    first_action_done = asyncio.Semaphore(0)\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    async def push(value):\n",
    "        await queue.put(value)\n",
    "\n",
    "    async def coroutineA():\n",
    "        \"\"\"Do first action then signal to B that we're done\"\"\"\n",
    "        asyncio.Task.current_task().name = \"coroutineA\"\n",
    "        await push('A')\n",
    "        first_action_done.release()\n",
    "\n",
    "    async def coroutineB():\n",
    "        asyncio.Task.current_task().name = \"coroutineB\"\n",
    "        async with first_action_done:\n",
    "            res = await push('B')\n",
    "\n",
    "\n",
    "    await asyncio.gather(coroutineA(), coroutineB())\n",
    "    res = [await queue.get() for _ in range(queue.qsize())]\n",
    "    assert res == ['A', 'B'], f'Test failed for attempt {attempt}: got {res}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_signaling, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Rendez Vous\n",
    "Two threads must await each other before doing some action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_rendez_vous(attempt):\n",
    "    \"\"\"Make sure action doesn't happen before a rendez vous. \n",
    "    \n",
    "    In this test, the action is reading the key value pairs from a shared dictionary. \n",
    "    Each of the two coroutines adds a key-value pair to the dictionary before the rendez vous. \n",
    "    So if both coroutines have waited for the other one successfully, they should both \n",
    "    return the two same (key,value) pairs. \n",
    "    \"\"\"\n",
    "    b_has_arrived = asyncio.Semaphore(0)\n",
    "    a_has_arrived = asyncio.Semaphore(0)\n",
    "    shared_dict = {}\n",
    "    lock = asyncio.Lock()  # a lock to protect updating the dictionary\n",
    "    \n",
    "    async def read_items_from_dict():\n",
    "        \"\"\"Return tuple of (key, value) pairs giving the items in the dictionary.\"\"\"\n",
    "        async with lock:\n",
    "            res = tuple(sorted(shared_dict.items()))\n",
    "        return res \n",
    "\n",
    "    async def coroutineA(key, value):\n",
    "        \"\"\"Store key value pair in shared dictionary, wait for rendez vous with B, \n",
    "        then read all key value pairs from dictionary. \n",
    "        \"\"\"\n",
    "        a_has_arrived.release()\n",
    "        # put in a value in the queue\n",
    "        async with lock:\n",
    "              shared_dict[key] = value\n",
    "        await b_has_arrived.acquire()\n",
    "        res = await read_items_from_dict()\n",
    "        return res\n",
    "\n",
    "    async def coroutineB(key, value):\n",
    "        \"\"\"Store key value pair in shared dictionary, wait for rendez vous with A, \n",
    "        then read all key value pairs from dictionary. \n",
    "        \"\"\"\n",
    "        b_has_arrived.release()\n",
    "        async with lock:\n",
    "              shared_dict[key] = value\n",
    "        await a_has_arrived.acquire()\n",
    "        res = await read_items_from_dict()\n",
    "        return res\n",
    "\n",
    "    itemsA, itemsB = await asyncio.gather(\n",
    "        coroutineA('A', 1), \n",
    "        coroutineB('B', 2)\n",
    "    )\n",
    "    expected_items = ('A', 1), ('B', 2)\n",
    "    results = {k:v for k,v in locals().items() if k in ['attempt', 'itemsA', 'itemsB', 'expected_items']}\n",
    "    assert itemsA == itemsB == expected_items, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_rendez_vous, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Mutex\n",
    "Protects access to critical regions. Mutal exclusion: two threads can't both have access to the mutex at the same time. \n",
    "\n",
    "How to test:\n",
    "- Use a lot of threads and make them race hard: see `test_mutex_threadpoool`\n",
    "- Better demonstrated without asyncio as the event loop tends to make some of these issues go away because operations between awaits are atomic (there's only one thread). \n",
    "  - we can demonstrate with asyncio by forcing a context switch: see `test_mutex_aio`\n",
    "  - we also can also run the threadpool test using aio `test_mutex_threadpool_aio`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Thread pool test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "def test_mutex_threadpool():\n",
    "    \"\"\"Check we can protect a variable using a mutex. \n",
    "    \n",
    "    Better demonstrated with threads rather than coroutines because with asyncio's event loop\n",
    "    operations between \"awaits\" are atomic.\n",
    "    \n",
    "    Use a big threadpool and make the threads race hard \n",
    "    by all incrementing the counter many times.\n",
    "     \n",
    "    \"\"\"\n",
    "    max_workers=100\n",
    "    pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "    counter = 0\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    iterations = 100_000\n",
    "    def increment_shared_counter(_):\n",
    "        nonlocal counter\n",
    "        with lock:\n",
    "            for _ in range(iterations):\n",
    "                counter += 1\n",
    "        #time.sleep(random.random())\n",
    "        return counter\n",
    "    intermediate_results = list(pool.map(increment_shared_counter, range(max_workers)))\n",
    "    #print(sorted(intermediate_results))\n",
    "    assert counter == iterations * max_workers, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['counter', 'intermediate_results']\n",
    "    }\n",
    "    \n",
    "test_mutex_threadpool() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Thread pool + asyncio test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_mutex_threadpool_aio():\n",
    "    \"\"\"Check we can protect a variable using a mutex. \n",
    "    \n",
    "    Use a big threadpool and make the threads race hard \n",
    "    by all incrementing the counter many times. \n",
    "    \n",
    "    Use asyncio to run the experiment via loop.run_in_executor \n",
    "    \"\"\"\n",
    "    pool = ThreadPoolExecutor(max_workers=100)\n",
    "    lock = threading.Lock()\n",
    "    counter = 0\n",
    "\n",
    "    def increment_shared_counter(_):\n",
    "        nonlocal counter\n",
    "        with lock:\n",
    "            for _ in range(100_000):\n",
    "                counter = counter + 1\n",
    "        #time.sleep(random.random())\n",
    "        return counter\n",
    "    \n",
    "    loop = asyncio.get_event_loop()\n",
    "    tasks = [\n",
    "        loop.run_in_executor(pool, increment_shared_counter, i) \n",
    "        for i in range(100)\n",
    "    ]\n",
    "    intermediate_results = await asyncio.gather(*tasks)\n",
    "    #print(sorted(intermediate_results))\n",
    "    assert counter == 100_000 * 100, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['counter', 'intermediate_results']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await test_mutex_threadpool_aio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Minimal asyncio test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_mutex_aio():\n",
    "    \"\"\"Check we can protect a variable using a mutex. \n",
    "    \n",
    "    Minimal test with asyncio to force a context switch between \n",
    "    reading and updating the counter. \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    lock = asyncio.Lock()\n",
    "    \n",
    "    async def increment_shared_counter():\n",
    "        nonlocal counter\n",
    "        async with lock:   # fails \n",
    "            # this is a bit convoluted but is a simple way to \n",
    "            # simulating non-thread safe concurrent updates to counter:\n",
    "            # we're sleeping between reading and incrementing the value of counter\n",
    "            # which allows a context switch: without the lock this will fail the test\n",
    "            x = counter\n",
    "            # forcing a context switch by sleeping \n",
    "            await asyncio.sleep(0.001)\n",
    "            counter = x + 1\n",
    "        return counter\n",
    "    tasks = [increment_shared_counter() for _ in range(2)]\n",
    "    intermediate_results = await asyncio.gather(*tasks)\n",
    "    #print(sorted(intermediate_results))\n",
    "    assert counter == 1 * 2, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['counter', 'intermediate_results']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await test_mutex_aio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Multiplex\n",
    "A kind of bounded mutex where up to a certain number of threads are allowed to own a lock. \n",
    "\n",
    "Think of a bouncer who allows up to certain number of people to get into a nightclub (or a supermarket during Covid 19 outbreak), and bounces people off when the max capacity has been reached. Then whenever someone leaves the room, another person is allowed to get in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_multiplex(attempt):\n",
    "    \"\"\"Check the max number of active threads in the critical region is as expected.\n",
    "    \n",
    "    Use a counter and a variable to keep track of the max number of threads, and \n",
    "    verify it's <= the size of the multiplex. \n",
    "    \"\"\"\n",
    "    multiplex = asyncio.Semaphore(5)\n",
    "    # we're using asyncio so no real need for locks \n",
    "    # to protect these variables: operations on them will be atomic \n",
    "    # in between awaits. \n",
    "    counter = 0\n",
    "    max_counter = 0\n",
    "    \n",
    "    async def multiplexed(name):\n",
    "        nonlocal counter\n",
    "        nonlocal max_counter\n",
    "        async with multiplex:\n",
    "            counter += 1    # enterning critical zone \n",
    "            if counter >= max_counter:\n",
    "                max_counter = counter\n",
    "            await asyncio.sleep(0.1)  # block to allow context switch\n",
    "            counter -= 1  # exiting critical zone \n",
    "        return max_counter\n",
    "    tasks = [multiplexed(name) for name in range(7)]\n",
    "    intermediate_results = await asyncio.gather(*tasks)\n",
    "    assert max_counter == 5, {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['max_counter', 'intermediate_results', 'attempt']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_multiplex, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "loop = asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Barrier\n",
    "Generalised rendez vous: all coroutines have to wait at the barrier until all of them have arrived. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_barrier(attempt):\n",
    "    \"\"\"All coroutines must wait at the barrier until they're all waiting behind it. \n",
    "    Then the barrier opens. \n",
    "    \n",
    "    Testing strategy: all coroutines add their own key,value pair to a shared dictionary. \n",
    "    Once a coroutine passes the barrier, it retrieves all key value pairs from the dictionary. \n",
    "    If the barrier's been effective, all coroutines should read the same content made of one key value pair per coroutine. \n",
    "    \"\"\"\n",
    "    barrier = asyncio.Semaphore(0)  \n",
    "    barrier_size = 5         # open barrier if nb threads behind barrier reaches this count\n",
    "    lock = asyncio.Lock()    # to protect access to dictionary\n",
    "    shared_dict = {}\n",
    "    arrived_count = 0\n",
    "    \n",
    "    async def read_items_from_dict():\n",
    "        \"\"\"Return tuple of (key, value) pairs giving the items in the dictionary.\"\"\"\n",
    "        async with lock:\n",
    "            res = tuple(sorted(shared_dict.items()))\n",
    "        return res\n",
    "    \n",
    "    async def push_wait_then_read(key, value):\n",
    "        nonlocal arrived_count\n",
    "        async with lock:\n",
    "            shared_dict[key] = value \n",
    "        arrived_count += 1\n",
    "        if arrived_count == barrier_size:\n",
    "            barrier.release()\n",
    "        else:\n",
    "            await barrier.acquire()\n",
    "            barrier.release()\n",
    "        items = await read_items_from_dict()\n",
    "        return items \n",
    "    \n",
    "    expected_items = tuple((key, value) for key, value in zip(list('ABCDE'), range(5)))\n",
    "    tasks = [push_wait_then_read(key, value) for (key, value) in expected_items]\n",
    "    received_items_per_coroutine = await asyncio.gather(*tasks)\n",
    "    assert all(\n",
    "        (received_items == expected_items) \n",
    "        for received_items \n",
    "        in received_items_per_coroutine\n",
    "    ), {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['received_items_per_coroutine', 'attempt']\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_barrier, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Reusable Barrier\n",
    "Generalised rendez vous: all coroutines have to wait at the barrier until all of them have arrived. Barrier is in a loop so needs to be reused. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "async def test_reusable_barrier(attempt):\n",
    "    \"\"\"All coroutines must wait at the barrier until they're all waiting behind it. \n",
    "    Then the barrier opens. \n",
    "    \n",
    "    Testing strategy: all coroutines add their own key,value pair to a shared dictionary. \n",
    "    Once a coroutine passes the barrier, it retrieves all key value pairs from the dictionary. \n",
    "    If the barrier's been effective, all coroutines should read the same content made of one key value pair per coroutine. \n",
    "    \"\"\"\n",
    "    turnstile = asyncio.Semaphore(0)  \n",
    "    barrier_size = 5         # open barrier if nb threads behind barrier reaches this count\n",
    "    lock = asyncio.Lock()    # to protect access to dictionary\n",
    "    shared_dict = {}\n",
    "    arrived_count = 0\n",
    "    released_count = 0\n",
    "    \n",
    "    async def read_items_from_dict():\n",
    "        \"\"\"Return tuple of (key, value) pairs giving the items in the dictionary.\"\"\"\n",
    "        async with lock:\n",
    "            res = tuple(sorted(shared_dict.items()))\n",
    "        return res\n",
    "    \n",
    "    async def push_wait_then_read(key, value):\n",
    "        nonlocal arrived_count\n",
    "        nonlocal released_count \n",
    "        async with lock:\n",
    "            shared_dict[key] = value \n",
    "        arrived_count += 1\n",
    "        if arrived_count == barrier_size:\n",
    "            turnstile.release()\n",
    "            released_count += 1\n",
    "        else:\n",
    "            await turnstile.acquire()\n",
    "            released_count += 1 \n",
    "            if released_count < barrier_size:\n",
    "                turnstile.release()\n",
    "            else:\n",
    "                # we're done: last thread exiting the turnstile,\n",
    "                # so let's reset the counters so we can reuse \n",
    "                # the barrier again \n",
    "                arrived_count = 0\n",
    "                released_count = 0\n",
    "        items = await read_items_from_dict()\n",
    "        return items \n",
    "    \n",
    "    expected_items = tuple((key, value) for key, value in zip(list('ABCDE'), range(5)))\n",
    "    # first time \n",
    "    tasks1 = [push_wait_then_read(key, value) for (key, value) in expected_items]\n",
    "    received_items_per_coroutine1 = await asyncio.gather(*tasks1)\n",
    "    assert all(\n",
    "        (received_items == expected_items) \n",
    "        for received_items \n",
    "        in received_items_per_coroutine1\n",
    "    ), {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['received_items_per_coroutine1', 'attempt']\n",
    "    }\n",
    "    # second time \n",
    "    shared_dict = {}  # clear the dict\n",
    "    tasks2 = [push_wait_then_read(key, value) for (key, value) in expected_items]\n",
    "    received_items_per_coroutine2 = await asyncio.gather(*tasks2)\n",
    "    \n",
    "    assert all(\n",
    "        (received_items == expected_items) \n",
    "        for received_items \n",
    "        in received_items_per_coroutine2\n",
    "    ), {\n",
    "        k:v for k,v in locals().items() if k in \n",
    "        ['received_items_per_coroutine2', 'attempt']\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "await run_test(test_reusable_barrier, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
